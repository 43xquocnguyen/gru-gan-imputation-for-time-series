{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\43xqu\\AppData\\Local\\Temp\\ipykernel_9644\\2797587156.py:35: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import *\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import (\n",
    "    Dropout, Input, LSTM, GRU, LeakyReLU,\n",
    "    Multiply, Add, Lambda, RNN, Bidirectional\n",
    ")\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, LSTM, RepeatVector, Conv1D, BatchNormalization,\n",
    "    Concatenate, Flatten, TimeDistributed, Dense\n",
    ")\n",
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.options.display.max_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_index_noise(x, ratio, placeholder=np.nan):\n",
    "    size = round(len(x) * ratio)\n",
    "    idx = np.random.randint(low=0, high=len(x), size=size)\n",
    "    x[idx] = placeholder\n",
    "    return x\n",
    "\n",
    "def random_interval_noise(x, min_size, max_size, placeholder=np.nan):\n",
    "    width = np.random.randint(min_size, max_size)\n",
    "    where = np.random.randint(0, len(x) - width)\n",
    "    x[where: where + width] = placeholder\n",
    "    return x\n",
    "\n",
    "def apply(X, params):\n",
    "    '''\n",
    "    * Lặp hàm `apply_ion_series()` cho tất cả các dòng numpy array 2D\n",
    "\n",
    "    Chọn ngẫu nhiên 2 lựa chọn:\n",
    "    1. Random Indices Noise: Cho một `missing value rato`\n",
    "    2. Random Interval Noise: Cho một độ rộng `width` liên tiếp\n",
    "    '''\n",
    "\n",
    "    def apply_on_series(x):\n",
    "        if np.random.choice([0, 1], p = [1 - params['prob_noise'], params['prob_noise']]):\n",
    "            nan_ratio = params['missing_value_ratio']\n",
    "            x = random_index_noise(x, nan_ratio)\n",
    "        else:\n",
    "            min_size = params['missing_value_min_size']\n",
    "            max_size = params['missing_value_max_size']\n",
    "            x = random_interval_noise(x, min_size, max_size)\n",
    "        return x\n",
    "\n",
    "    X = X.values\n",
    "    X = np.apply_along_axis(apply_on_series, 1, X)\n",
    "    mask = np.isnan(X)\n",
    "    return pd.DataFrame(X), pd.DataFrame(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data_raw/final.csv')\n",
    "params = yaml.load(open('../gan/config.yaml'), yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = df[['YEAR', 'MO', 'DY']]\n",
    "df = df.drop(['YEAR', 'MO', 'DY'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, mask = apply(df, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam_optimizer(alpha):\n",
    "  return Adam(lr=alpha)\n",
    "\n",
    "def create_generator(adam, timesteps, features, range_matrix, min_matrix):\n",
    "  #-------------------------------------------------------------\n",
    "  #units là số lượng phần tử trong sequence (timestep),\n",
    "  input1 = Input((timesteps, features,))   #Đầu vào 1 là ma trận bị missing value\n",
    "  mask = Input((timesteps, features,))  #Đầu vào thứ 2 là ma trận mask\n",
    "  gru = Bidirectional(GRU(units = features, return_sequences=True))(input1)   \n",
    "  gru1 = GRU(units = features, return_sequences=True)(gru)  #GRU nối với input1 để tạo ra ma trận mới, qua sigmoid nên sẽ nằm trong (0,1)\n",
    "  gru2 = GRU(units = features, return_sequences=True, activation = \"sigmoid\")(gru1)\n",
    "  lambda_ouput = Lambda(lambda x: (x * range_matrix) + min_matrix)(gru2) #Cái này để scale (0,1) thành trong (min,max) nè\n",
    "  filled = Multiply()([lambda_ouput, mask]) #Nhân ma trận đã được điền khuyết bởi GRU (LSTM, RNN) với ma trận mask (ma trận này chỉ tồn tại giá trị được điền khuyết)\n",
    "  final = Add()([input1, filled])  #Cuối cùng cộng ma trận ban đầu (input1) với ma trận chỉ tồn tại giá trị được điền khuyết (filled), nhằm tạo ra ma trận đã được điền khuyết\n",
    "\n",
    "  model = Model(inputs = [input1,mask], outputs = final)\n",
    "  #-------------------------------------------------------------\n",
    "  # input1 = Input((timesteps, features,))   #Đầu vào 1 là ma trận bị missing value\n",
    "  # mask = Input((timesteps, features,))  #Đầu vào thứ 2 là ma trận mask\n",
    "  # gru = LSTM(units = features, return_sequences=True)(input1)   \n",
    "  # # gru1 = GRU(units = features, return_sequences=True)(gru)  #GRU nối với input1 để tạo ra ma trận mới, qua sigmoid nên sẽ nằm trong (0,1)\n",
    "  # # gru2 = GRU(units = features, return_sequences=True, activation = \"sigmoid\")(gru1)\n",
    "  # # lambda_ouput = Lambda(lambda x: (x * range_matrix) + min_matrix)(gru2) #Cái này để scale (0,1) thành trong (min,max) nè\n",
    "  # # filled = Multiply()([lambda_ouput, mask]) #Nhân ma trận đã được điền khuyết bởi GRU (LSTM, RNN) với ma trận mask (ma trận này chỉ tồn tại giá trị được điền khuyết)\n",
    "  # # final = Add()([input1, filled])  #Cuối cùng cộng ma trận ban đầu (input1) với ma trận chỉ tồn tại giá trị được điền khuyết (filled), nhằm tạo ra ma trận đã được điền khuyết\n",
    "  \n",
    "  # model = Model(inputs = [input1,mask], outputs = gru)\n",
    "  #-------------------------------------------------------------\n",
    "\n",
    "  model.compile(loss='binary_crossentropy', optimizer=adam)\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discriminator \n",
    "def create_discriminator(adam, timesteps, features):\n",
    "  input = Input((timesteps, features,))\n",
    "  # conv1d = Conv1D(filters=20, kernel_size=1)(input)\n",
    "  gru = Bidirectional(GRU(units = features, return_sequences=True))(input)\n",
    "  # leaky = LeakyReLU(alpha=0.2)(conv1d)\n",
    "  leaky = LeakyReLU(alpha=0.2)(gru)\n",
    "  dropout = Dropout(0.5)(leaky)\n",
    "  flatten = Flatten()(dropout)\n",
    "  dense = Dense(1, activation='sigmoid')(flatten) \n",
    "  model = Model(inputs = input, outputs = dense)\n",
    "  model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAN\n",
    "def create_gan(discriminator, generator, adam):\n",
    "  discriminator.trainable=False\n",
    "  x = generator\n",
    "  gan_output = discriminator(x.output)\n",
    "  gan= Model(inputs=x.input, outputs=gan_output)\n",
    "  gan.compile(loss='binary_crossentropy', optimizer=adam)\n",
    "  return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gán nhãn \n",
    "def gen_label(size, is_real=True, noise_ratio=0.1):\n",
    "  if is_real:\n",
    "    label = np.ones(size,)*1\n",
    "  else:\n",
    "    label = np.ones(size,)*0\n",
    "  return np.squeeze(label)\n",
    "\n",
    "# tạo input cho Generator\n",
    "def gen_z_input(batch_size, step, dset, dset_mask):\n",
    "  return [dset[step*batch_size:(step+1)*batch_size], dset_mask[step*batch_size:(step+1)*batch_size]]\n",
    "\n",
    "# tạo ra dset fake và label\n",
    "def gen_fake_batch(generator, batch_size, step, dset, dset_mask):\n",
    "  z = gen_z_input(batch_size, step, dset, dset_mask)\n",
    "  fake_dset = generator.predict(z)\n",
    "  fake_label = gen_label(batch_size, is_real=False)\n",
    "  return fake_dset, fake_label\n",
    "\n",
    "# tạo ra dset real và label\n",
    "def gen_real_batch(batch_size, step, dset):\n",
    "  real_dset = dset[step*batch_size:(step+1)*batch_size]\n",
    "  real_label = gen_label(batch_size, is_real=True)\n",
    "  return real_dset, real_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_error(pred_matrix, true_matrix, mask_matrix, range_matrix, min_matrix):\n",
    "  missing_pred = np.multiply(pred_matrix, mask_matrix)\n",
    "  missing_true = np.multiply(true_matrix, mask_matrix)\n",
    "  #Normalize\n",
    "  norm_pred = ((missing_pred - min_matrix)/range_matrix)*mask_matrix\n",
    "  norm_true = ((missing_true - min_matrix)/range_matrix)*mask_matrix\n",
    "  num_mask = len(mask_matrix[mask_matrix == True])\n",
    "\n",
    "  error = np.sum(np.sqrt((norm_pred - norm_true)*(norm_pred - norm_true ))/ num_mask)\n",
    "  return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill(i, j, Xtest, Xreal, pred, print_full, boundery):\n",
    "  missingpred = np.multiply(pred[j], Xtest[1][j])\n",
    "  missingtrue = np.multiply(Xreal[0][j], Xtest[1][j])\n",
    "  err = calc_error(pred[j], Xreal[0][j], Xtest[1][j])\n",
    "  #Đã normalize các biến thành (0,1), sau đó tính RMSE\n",
    "  print(\"Errors (Normalized): {}\".format(err))\n",
    "  print(\"------------------------------------------------------------------------------------\")\n",
    "  print(\"Boundery\")\n",
    "  print(pd.DataFrame(boundery))\n",
    "  print(\"------------------------------------------------------------------------------------\")\n",
    "  print('Dữ liệu missing được điền khuyết')\n",
    "  print(pd.DataFrame(missingpred).round(decimals = 2).replace(0,'-'))\n",
    "  print(\"------------------------------------------------------------------------------------\")\n",
    "  print(\"Dữ liệu missing thực tế\")\n",
    "  print(pd.DataFrame(missingtrue).replace(0,'-') )\n",
    "  print(\"------------------------------------------------------------------------------------\")\n",
    "  if(print_full == 1):\n",
    "    print(\"Dữ liệu gốc\")\n",
    "    print(pd.DataFrame(Xreal[0][j]))\n",
    "    print(\"------------------------------------------------------------------------------------\")\n",
    "    print('Dữ liệu đã được điền')\n",
    "    print(pd.DataFrame(pred[j].round(decimals = 2)))\n",
    "    print(\"------------------------------------------------------------------------------------\")\n",
    "  return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data_raw/final.csv')\n",
    "df = data[[\"Temperature\",\"Relative_Humidity\",\"Specific_Humidity\",\"Precipitation\",\"Pressure\",\"Wind_Speed\",\"Wind_Direction\"]]\n",
    "\n",
    "missing_ratio = 0.7\n",
    "\n",
    "lower_quantile = 0 \n",
    "upper_quantile = 1\n",
    "\n",
    "timesteps = 5\n",
    "features = 7\n",
    "batch_size = 8\n",
    "\n",
    "params = {\n",
    "    \"missing_value_ratio\": missing_ratio, \"prob_noise\": 0,\n",
    "    \"missing_value_min_size\": 0,\"missing_value_max_size\": 5, \n",
    "    \"prob_noise\": 0.5, \"placeholder_value\": -0.1}\n",
    "\n",
    "missing_df, mask = apply(df, params)\n",
    "missing = missing_df\n",
    "\n",
    "boundery = np.array(missing.quantile([lower_quantile, upper_quantile]))\n",
    "mask = np.array(mask.replace([False,True], [0,1]))\n",
    "missing = np.array(missing.replace(np.nan, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "X_mask = []\n",
    "for i in range(len(missing)-timesteps):\n",
    "  a_missing_sample = missing[i:i+timesteps]\n",
    "  a_mask_sample = mask[i:i+timesteps]\n",
    "  X.append(a_missing_sample)\n",
    "  X_mask.append(a_mask_sample)\n",
    "X = np.stack(X)\n",
    "X_mask = np.stack(X_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real = []\n",
    "for i in range(len(np.array(df[[\"Temperature\",\"Relative_Humidity\",\"Specific_Humidity\",\"Precipitation\",\"Pressure\",\"Wind_Speed\",\"Wind_Direction\"]]))-timesteps):\n",
    "  a_real_sample = np.array(df[[\"Temperature\",\"Relative_Humidity\",\"Specific_Humidity\",\"Precipitation\",\"Pressure\",\"Wind_Speed\",\"Wind_Direction\"]])[i:i+timesteps]\n",
    "  X_real.append(a_real_sample)\n",
    "X_real = np.stack(X_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "X_mask = []\n",
    "for i in range(len(missing)-timesteps):\n",
    "  a_missing_sample = missing[i:i+timesteps]\n",
    "  a_mask_sample = mask[i:i+timesteps]\n",
    "  X.append(a_missing_sample)\n",
    "  X_mask.append(a_mask_sample)\n",
    "X = np.stack(X)\n",
    "X_mask = np.stack(X_mask)\n",
    "\n",
    "X_real = []\n",
    "for i in range(len(np.array(df[[\"Temperature\",\"Relative_Humidity\",\"Specific_Humidity\",\"Precipitation\",\"Pressure\",\"Wind_Speed\",\"Wind_Direction\"]]))-timesteps):\n",
    "  a_real_sample = np.array(df[[\"Temperature\",\"Relative_Humidity\",\"Specific_Humidity\",\"Precipitation\",\"Pressure\",\"Wind_Speed\",\"Wind_Direction\"]])[i:i+timesteps]\n",
    "  X_real.append(a_real_sample)\n",
    "X_real = np.stack(X_real)\n",
    "\n",
    "#---------------------------------------------------\n",
    "X_train = X[0:int(len(X)*0.8)]\n",
    "X_test = X[int(len(X)*0.8):len(X)]\n",
    "\n",
    "X_train_real = X[0:int(len(X_real)*0.8)]\n",
    "X_test_real = X_real[int(len(X_real)*0.8):len(X_real)]\n",
    "\n",
    "X_mask_train = X_mask[0:int(len(X_mask)*0.8)]\n",
    "X_mask_test = X_mask[int(len(X_mask)*0.8):len(X_mask)]\n",
    "\n",
    "#---------------------------------------------------\n",
    "min_matrix = np.array([boundery[0] for i in range(timesteps)])\n",
    "max_matrix = np.array([boundery[1] for i in range(timesteps)])\n",
    "range_matrix = np.array([[boundery[1][i] - boundery[0][i] for i in range(boundery.shape[1])] for j in range(timesteps)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrate = 0.0000789 #0.0000789\n",
    "step_per_epoch = len(X_train)//batch_size - 1\n",
    "\n",
    "optimizer = adam_optimizer(lrate)\n",
    "generator = create_generator(optimizer, timesteps, features, range_matrix, min_matrix)\n",
    "discriminator = create_discriminator(optimizer, timesteps, features)\n",
    "GAN_model = create_gan(discriminator, generator, optimizer)\n",
    "\n",
    "epochs= 1\n",
    "num_epoch = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c9d4a98e237f71a2030629663d03eb64c57968c1c9480ff7d5c81d06fb8994b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
